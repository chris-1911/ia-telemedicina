# -*- coding: utf-8 -*-
"""servidor_ia

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lmvZ0sINHSSwP_cIm9bizj82D3XUI3lv
"""

# servidor_ia.py — versión híbrida con calibración contextual (OpenAI)
from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
import os

# Crear app FastAPI
app = FastAPI(title="Servidor IA Telemedicina - Híbrido")

# Configurar cliente OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Estructura de datos
class Solicitud(BaseModel):
    diagnostico: str
    probabilidad: float
    sintomas_locales: list[str] = []
    sintomas_extras: list[str] = []


@app.post("/explicar")
def explicar(data: Solicitud):
    # Combinar todos los síntomas
    todos_los_sintomas = data.sintomas_locales + data.sintomas_extras

    # Ajustar contexto según si hay síntomas adicionales
    if data.probabilidad == 0.0:
        contexto_confianza = (
            "El modelo local no pudo estimar una probabilidad exacta, "
            "ya que los síntomas ingresados no coincidieron con el dataset. "
            "Sin embargo, ofrece una orientación general basada en la descripción del paciente."
        )
    elif data.sintomas_extras and len(data.sintomas_extras) > 0:
        contexto_confianza = (
            f"El modelo local predijo un {data.probabilidad*100:.1f}% de confianza para {data.diagnostico}, "
            "pero el paciente añadió síntomas adicionales no contemplados en el dataset. "
            "Reanaliza el caso completo considerando toda la información disponible. "
            "Puedes asumir que la confianza global podría aumentar ligeramente, sin dar porcentajes exactos."
        )
    else:
        contexto_confianza = (
            f"El modelo local predijo un {data.probabilidad*100:.1f}% de confianza para {data.diagnostico}."
        )

    # Construcción del prompt
    prompt = f"""
    Paciente con {', '.join(todos_los_sintomas)}.
    Diagnóstico probable: {data.diagnostico}.
    {contexto_confianza}

    Eres un asistente médico empático y profesional.
    Explica en lenguaje breve y sencillo qué podría estar ocurriendo,
    brinda orientación práctica sobre qué hacer y qué evitar,
    y recuerda al paciente que puede agendar una cita médica desde la aplicación.
    """

    try:
        respuesta = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un asistente médico que brinda orientación inicial, no diagnósticos definitivos."
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=400,
            temperature=0.6,
        )

        texto = respuesta.choices[0].message.content.strip()
        return {"estado": "exito", "explicacion": texto}

    except Exception as e:
        return {"estado": "error", "mensaje": f"Excepción: {str(e)}"}